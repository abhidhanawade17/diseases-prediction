# -*- coding: utf-8 -*-
"""cardiovascular-eda-predictive-analysis (3).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DLmn8V5uXUTbkh13KgFB8-VTay10b98J

**Information of the dataset**

General_Health: An object (typically a string) that might describe the general health condition of an individual. This could be categorical data like 'Good', 'Average', 'Poor', etc.

Checkup: An object that might indicate when the person last had a medical checkup. It could be intervals like 'Within the past year', '2-3 years ago', etc.

Exercise: An object that perhaps indicates if a person exercises regularly. This might be a binary 'Yes' or 'No' or more detailed.

Heart_Disease: An object indicating if a person has heart disease. This is likely a 'Yes' or 'No' column, but it could also have more detailed categories.

Skin_Cancer, Other_Cancer, Depression, Diabetes, Arthritis: These are all objects, likely indicating the presence or absence of the corresponding condition, e.g., 'Yes' or 'No'.

Sex: An object column that specifies the gender of the individual, likely values being 'Male' and 'Female'.

Age_Category: An object that categorizes individuals into age groups, e.g., '18-24', '25-30', etc.

Height_(cm): A float64 column that records the height of the individual in centimeters.

Weight_(kg): A float64 column that records the weight of the individual in kilograms.

BMI: A float64 column representing the Body Mass Index. It's a derived value considering weight and height and gives an indication of whether an individual's weight is healthy for their height.

Smoking_History: An object (likely a string) that describes the smoking habits of the individual. Could be values like 'Never', 'Occasionally', 'Regularly', etc.

Alcohol_Consumption: A float64 column. The exact nature isn't clear from the name alone, but it could represent the average units of alcohol consumed per week, or it might be a categorical representation encoded as numbers.

Fruit_Consumption, Green_Vegetables_Consumption, FriedPotato_Consumption: Float64 columns that might indicate the amount or frequency of consumption of these foods. The exact measurement unit or frequency isn't clear just from the name.

**Unit of Measurement of Consumption Variable:**

**Loading necessary libraries**
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.subplots as sp
import plotly.graph_objs as go
colors = px.colors.sequential.Plasma_r

"""import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

Reading csv file by read_csv function from file location
"""

df_heart=pd.read_csv("/CVD_cleaned[1].csv")

"""Top 5 headers"""

df_heart.head(5)

"""Last 5 rows from the dataset"""

df_heart.tail(5)

"""Datatypes of the dataset"""

df_heart.dtypes

"""There are object and float datatypes.

Columns of the dataset
"""

df_heart.columns

"""Checking null values from the dataset"""

print(df_heart.isnull().sum())

"""There are no null values in the dataset as all 0 represents no null values.

Dropping null values from the dataset.
"""

df_heart=df_heart.dropna()

"""Checking total number of rows and columns from the dataset."""

df_heart.shape

"""There are total 308854 rows and 19 columns in the dataset.

Renaming columns
"""

#Changing the name of a big column df_heart.rename(columns={'height-(cm)': 'Height_cm', 'weight-(kg)': 'Weight_kg'}, inplace=True))
df_heart.rename(columns={'Height_(cm)': 'Height_cm', 'Weight_(kg)': 'Weight_kg'}, inplace=True)

"""Displaying columns from the dataset after renaming column name"""

print(df_heart.columns)

"""# Feature Engineering

Age Wise Distribution
"""

# Categorize age based on the specified ranges
def categorize_age(age):
    if age in ['18-24']:
        return 'Young'
    if age in ['25-29', '30-34', '35-39']:
        return 'Adult'
    elif age in ['40-44', '45-49', '50-54']:
        return 'Mid-Aged'
    elif age in ['55-59', '60-64','65-69']:
        return 'Senior-Adult'
    elif age in ['70-74', '75-79','80+']:
        return 'Elderly'

"""We have categorize age as 18-24 as Young, 25-39 as Adult, 40-54 as Mid-Aged, 55-69 as Senior-Adult and 70-above as Elderly.

Bin Range Distribution
"""

max_bmi = df_heart['BMI'].max()
print("The maximum BMI in the dataset is:", max_bmi)

m_bmi = df_heart['BMI'].min()
print("The minimum BMI in the dataset is:", m_bmi)

"""bmi_bins = [12.02, 18.3, 26.85, 31.58, 37.8, 100]: This defines the boundaries for each BMI category.

bmi_labels = ['Underweight', 'Normal weight', 'Overweight', 'Obese I', 'Obese II']: These are the labels for each BMI category.

heart['bmi_group'] = pd.cut(heart['bmi'], bins=bmi_bins, labels=bmi_labels, right=False):
This line does the actual categorization. The pd.cut function takes the bmi column from the heart DataFrame, classifies each value into one of the specified bins, and assigns the corresponding label to it. The resulting labels are then stored in a new column in the heart DataFrame called bmi_group.
"""

# Define BMI ranges and labels for each group
bmi_bins = [12.02, 18.3, 26.85, 31.58, 37.8, 100]
bmi_labels = ['Underweight', 'Normal weight', 'Overweight', 'Obese I', 'Obese II']
df_heart['Bmi_Group'] = pd.cut(df_heart['BMI'], bins=bmi_bins, labels=bmi_labels, right=False)

column_to_move = df_heart.pop('Bmi_Group')
df_heart.insert(14, 'Bmi_Group', column_to_move)
df_heart['Bmi_Group'] = df_heart['Bmi_Group'].astype('object')

"""# Visualization Exploratory Data Analysis(EDA)"""

df_heart.describe(include = 'O')

"""Given that all counts are the same (308,854), it appears to be a clean dataset with no missing values for these categorical variables.

The data suggests that a significant portion of the population surveyed perceives their health as "Very Good," with a large number having had a checkup within the past year. The majority of the respondents engage in exercise and do not suffer from the listed health conditions. The data also indicate demographic details such as a higher frequency of females and a concentration of individuals in the 65-69 age bracket.
"""

categorical_columns = ['General_Health', 'Checkup', 'Exercise', 'Heart_Disease', 'Skin_Cancer', 'Other_Cancer', 'Depression', 'Diabetes', 'Arthritis', 'Sex']
for col in categorical_columns:
    plt.figure(figsize=(8, 4))
    sns.countplot(data=df_heart, x=col)
    plt.title(f'Distribution of {col}')
    plt.xticks(rotation=45)
    plt.show()

"""The bar chart presents the self-assessed health status of survey respondents, showing that the majority consider their health to be "Very Good," followed by "Good" and "Excellent". Fewer respondents categorized their health as "Fair" or "Poor," indicating a generally positive perception of health among the surveyed group. The "Very Good" category is the most common response, suggesting a trend towards a favorable view of personal health in this population.

The next image shows a bar chart representing the frequency of health checkups among survey respondents. The largest bar indicates that most individuals had a checkup within the past year. Significantly fewer people had their last checkup within the past 2 years, and even fewer 5 or more years ago. The categories with the least responses are those who had checkups within the past 5 years and those who have never had a checkup. This suggests a strong inclination towards regular annual health checkups within the surveyed population.

Similarly, other bar charts display the distribution of various health-related responses:

Exercise: A majority of respondents engage in exercise.
Heart Disease: A large proportion of respondents do not have heart disease.
Other Cancer: Most respondents do not have a history of cancer other than skin cancer.
Diabetes: The majority of respondents do not have diabetes, with a small portion indicating 'Yes' and even smaller segments for prediabetes/borderline diabetes and gestational diabetes.
Arthritis: More respondents do not have arthritis compared to those who do.

# Identification of Risk Factors:

1. Health Assessment
2. Demographic
3. Life Style

# 1. Health Assessment
"""

# Create a histogram for the "General_Health" column
fig = px.histogram(df_heart, x="General_Health", title="Distribution of General Health", hover_data=["General_Health"])

# Display the plot
fig.show()

# Create a histogram for the "General_Health" column, colored by "Heart_Disease"
fig1 = px.histogram(df_heart, x="General_Health", color="Heart_Disease",
                   title="Distribution of General Health by Heart Disease Status",
                   hover_data=["General_Health", "Heart_Disease"])

# Display the plot
fig1.show()

"""# 2. Demographic Analysis:

"""

# Create a bar plot for the "Sex" column
fig = px.histogram(df_heart, x="Sex", title="Distribution of Gender")

# Display the plot
fig.show()

# Create a bar plot for the distribution of "Heart_Disease" by "Sex"
fig2 = px.histogram(df_heart,
                   x="Sex",
                   color="Heart_Disease",
                   title="Checking which gender is more susceptible to Heart Disease",
                   barmode='group',  # This will display separate bars for 'Yes' and 'No' side by side for each gender
                   )

# Display the plot
fig2.show()


# Compute the average BMI for each Sex and Heart_Disease group
average_bmi = df_heart.groupby(['Sex', 'Heart_Disease']).mean(numeric_only=True).reset_index()

# Create a bar plot
fig3 = px.bar(average_bmi,
             x='Sex',
             y='BMI',
             color='Heart_Disease',
             barmode='group',
             title='Checking Average BMI by Gender and Heart Disease Status',
             labels={'BMI': 'Average BMI'})

# Display the plot
fig3.show()

"""# Age Wise Distribution"""

# Apply the function to the Age_Category column
df_heart['Age_Group'] = df_heart['Age_Category'].apply(categorize_age)

# Create a mapping from Age_Group to its combined string of name and range
age_mapping = {
    'Young': 'Young (18-24)',
    'Adult': 'Adult (25-39)',
    'Mid-Aged': 'Mid-Aged (40-54)',
    'Senior-Adult': 'Senior-Adult (55-69)',
    'Elderly': 'Elderly (70+)'
}

df_heart['Age_Detail'] = df_heart['Age_Group'].map(age_mapping)

# Plotting the distribution of Age Groups with the combined string
fig = px.histogram(df_heart, x="Age_Detail", color="Age_Detail",
                   title="Distribution of Age Groups",
                   category_orders={'Age_Detail': list(age_mapping.values())})
fig.show()

# Plotting Age Groups Susceptibility to Heart Disease with the combined string
fig2 = px.histogram(df_heart, x="Age_Detail", color="Heart_Disease",
                   title="Age Groups Susceptibility to Heart Disease",
                   category_orders={'Age_Detail': list(age_mapping.values())},
                   barmode='group')  # Grouped bar chart
fig2.show()

# Calculate average BMI for each combination of Age Group and Heart Disease status
grouped_data = df_heart.groupby(['Age_Detail', 'Heart_Disease'])['BMI'].mean().reset_index()

# Create the bar plot for Average BMI across Age Groups based on Heart Disease with the combined string
fig3 = px.bar(grouped_data, x='Age_Detail', y='BMI', color='Heart_Disease',
             title="Average BMI across Age Groups based on Heart Disease",
             labels={'BMI': 'Average BMI'},
             category_orders={'Age_Detail': list(age_mapping.values())},
             barmode='group')  # Grouped bar chart
fig3.show()

"""# BMI Analysis"""

# Apply the function to the Age_Category column
df_heart['Age_Group'] = df_heart['Age_Category'].apply(categorize_age)

# Create a mapping from Age_Group to its combined string of name and range
age_mapping = {
    'Young': 'Young (18-24)',
    'Adult': 'Adult (25-39)',
    'Mid-Aged': 'Mid-Aged (40-54)',
    'Senior-Adult': 'Senior-Adult (55-69)',
    'Elderly': 'Elderly (70+)'
}

# Map the Age_Group to its detailed label
df_heart['Age_Label'] = df_heart['Age_Group'].map(age_mapping)

# Create a box plot visualizing BMI across age details and colored by heart disease status
fig = px.box(df_heart,
             x="Age_Label",
             y="BMI",
             color="Heart_Disease",
             title="BMI Distribution across Age Groups based on Heart Disease Status",
             category_orders={"Age_Label": list(age_mapping.values())})

# Update layout to make it more readable
fig.update_layout(xaxis_title="Age Group",
                  yaxis_title="BMI",
                  legend_title="Heart Disease")

# Display the plot
fig.show()

"""The image is a boxplot showing the distribution of Body Mass Index (BMI) across different age groups, categorized by heart disease status. Blue boxes represent individuals without heart disease, and red boxes represent those with heart disease. Across all age groups, those with heart disease tend to have a higher median BMI compared to those without. The spread of BMI values is quite wide in all categories, indicating variability in BMI within each age and heart disease category. The age groups shown are Young (18-24), Adult (25-39), Mid-Aged (40-54), Senior-Adult (55-69), and Elderly (70+). Outliers are present in each category, indicated by dots above and below the boxes."""

fig2 = px.histogram(df_heart, x="Bmi_Group", color='Heart_Disease', barmode='group',
                     title="Checking which Bmi Group is more Susceptible to Heart Disease?")
fig2.update_layout(xaxis_title="BMI Group", yaxis_title="Count", legend_title="Heart Disease",
                   xaxis_showgrid=False, yaxis_showgrid=False, plot_bgcolor='white')
fig2.show()

"""The image shows a bar chart comparing the number of individuals with and without heart disease across different BMI groups. The BMI groups shown are Underweight, Obese I, Normal weight, Obese II, and Overweight. For each BMI category, there are two bars: one for individuals without heart disease (in blue) and one for those with heart disease (in red). The count of individuals without heart disease is significantly higher across all BMI groups compared to those with heart disease. The Normal weight group has the highest number of individuals without heart disease, while the Obese I and Overweight groups have a noticeable but smaller number of individuals with heart disease. The chart suggests that heart disease is present across all BMI categories, but the absolute numbers are lower than those without heart disease in each group.

# 3. Impact of Lifestyle Analysis

To understand the impact of various lifestyle choices on heart disease susceptibility, we can analyze the given columns from the dataset. Here's a basic approach:

1. Smoking History vs. Heart Disease
2. Alcohol Consumption vs. Heart Disease
3. Fruit Consumption vs. Heart Disease
4. Green Vegetables Consumption vs. Heart Disease
5. Fried Potato Consumption vs. Heart Disease
6. Exercise vs. Heart Disease

For simplicity, I'll demonstrate how to create histograms for each of the categories against heart disease.
"""

# Smoking History vs. Heart Disease
fig1 = px.histogram(df_heart, x="Smoking_History", color='Heart_Disease', barmode='group',
                    title="Smoking History vs. Heart Disease")
fig1.update_layout(xaxis_title="Smoking History", yaxis_title="Count", legend_title="Heart Disease")
fig1.show()

"""The bar chart displays counts of individuals with and without heart disease, segmented by their smoking history. The majority of both smokers and non-smokers do not have heart disease, but the count of non-smokers is significantly higher in both categories. There are fewer individuals with heart disease in both smoking and non-smoking groups, indicating that while heart disease is less common overall, it affects both smokers and non-smokers."""

# Order of age categories for display
age_order = ['Young (18-24)', 'Adult (25-39)', 'Mid-Aged (40-54)', 'Senior-Adult (55-69)', 'Elderly (70+)']

# Map the Age_Group to its detailed label
df_heart['Age_Label'] = df_heart['Age_Group'].map(age_mapping)

# Group the data by Age_Label and Heart_Disease and compute the median alcohol consumption
grouped_data_alcohol = df_heart.groupby(['Age_Label', 'Heart_Disease'], as_index=False)['Alcohol_Consumption'].median()

# Order the dataframe according to the age_order list
grouped_data_alcohol['Age_Label'] = pd.Categorical(grouped_data_alcohol['Age_Label'], categories=age_order, ordered=True)
grouped_data_alcohol = grouped_data_alcohol.sort_values('Age_Label')

# Create the bar chart
fig_alcohol = px.bar(grouped_data_alcohol, x='Age_Label', y='Alcohol_Consumption', color='Heart_Disease', barmode='group', title="Impact of Alcohol Consumption on Heart Disease")

# Update layout to make it more readable
fig_alcohol.update_layout(xaxis_title="Age Group", yaxis_title="Median Alcohol Consumption", legend_title="Heart Disease", xaxis_showgrid=False, yaxis_showgrid=False, plot_bgcolor='white')

# Display the plot
fig_alcohol.show()

"""The bar chart compares the median alcohol consumption across different age groups, distinguishing between those with and without heart disease. The age groups are Young (18-24), Adult (25-39), Mid-Aged (40-54), Senior-Adult (55-69), and Elderly (70+). For all age groups, individuals without heart disease (blue bars) show higher median alcohol consumption compared to those with heart disease (red bars). However, the median levels of alcohol consumption are not specified on the y-axis, making it difficult to assess the actual consumption levels. The trend across age groups appears consistent with non-heart disease individuals consuming more alcohol than their counterparts with heart disease."""

# Order of age categories for display
age_order = ['Young (18-24)', 'Adult (25-39)', 'Mid-Aged (40-54)', 'Senior-Adult (55-69)', 'Elderly (70+)']

# Map the Age_Group to its detailed label
df_heart['Age_Label'] = df_heart['Age_Group'].map(age_mapping)

# Group the data by Age_Label and Heart_Disease and compute the median green vegetables consumption
grouped_data_vegetables = df_heart.groupby(['Age_Label', 'Heart_Disease'], as_index=False)['Green_Vegetables_Consumption'].median()

# Order the dataframe according to the age_order list
grouped_data_vegetables['Age_Label'] = pd.Categorical(grouped_data_vegetables['Age_Label'], categories=age_order, ordered=True)
grouped_data_vegetables = grouped_data_vegetables.sort_values('Age_Label')

# Create the bar chart
fig_vegetables = px.bar(grouped_data_vegetables, x='Age_Label', y='Green_Vegetables_Consumption', color='Heart_Disease', barmode='group', title="Impact of Green Vegetables Consumption on Heart Disease")

# Update layout to make it more readable
fig_vegetables.update_layout(xaxis_title="Age Group", yaxis_title="Median Green Vegetables Consumption", legend_title="Heart Disease", xaxis_showgrid=False, yaxis_showgrid=False, plot_bgcolor='white')

# Display the plot
fig_vegetables.show()

"""The bar chart shows the median green vegetable consumption for different age groups, comparing those with heart disease (red bars) and without (blue bars). Across all age groups — Young (18-24), Adult (25-39), Mid-Aged (40-54), Senior-Adult (55-69), and Elderly (70+) — individuals with heart disease have lower median vegetable consumption than those without. The chart suggests that higher green vegetable intake is associated with the absence of heart disease across these age groups."""

# Order of age categories for display
age_order = ['Young (18-24)', 'Adult (25-39)', 'Mid-Aged (40-54)', 'Senior-Adult (55-69)', 'Elderly (70+)']

# Map the Age_Group to its detailed label
df_heart['Age_Label'] = df_heart['Age_Group'].map(age_mapping)

# Group the data by Age_Label and Heart_Disease and compute the median fried potato consumption
grouped_data_potato = df_heart.groupby(['Age_Label', 'Heart_Disease'], as_index=False)['FriedPotato_Consumption'].median()

# Order the dataframe according to the age_order list
grouped_data_potato['Age_Label'] = pd.Categorical(grouped_data_potato['Age_Label'], categories=age_order, ordered=True)
grouped_data_potato = grouped_data_potato.sort_values('Age_Label')

# Create the bar chart
fig_potato = px.bar(grouped_data_potato, x='Age_Label', y='FriedPotato_Consumption', color='Heart_Disease', barmode='group', title="Impact of Fried Potato Consumption on Heart Disease")

# Update layout to make it more readable
fig_potato.update_layout(xaxis_title="Age Group", yaxis_title="Median Fried Potato Consumption", legend_title="Heart Disease", xaxis_showgrid=False, yaxis_showgrid=False, plot_bgcolor='white')

# Display the plot
fig_potato.show()

"""The bar chart compares median fried potato consumption between individuals with and without heart disease across various age groups. It shows that consumption is generally higher among those without heart disease in all age categories."""

# Map the Age_Group to its detailed label
df_heart['Age_Label'] = df_heart['Age_Group'].map(age_mapping)

# Group the data by Age_Label and Heart_Disease and compute the median fruit consumption
grouped_data_fruit = df_heart.groupby(['Age_Label', 'Heart_Disease'], as_index=False)['Fruit_Consumption'].median()

# Order the dataframe according to the age_order list
grouped_data_fruit['Age_Label'] = pd.Categorical(grouped_data_fruit['Age_Label'], categories=age_order, ordered=True)
grouped_data_fruit = grouped_data_fruit.sort_values('Age_Label')

# Create the bar chart
fig_fruit = px.bar(grouped_data_fruit, x='Age_Label', y='Fruit_Consumption', color='Heart_Disease', barmode='group', title="Impact of Fruit Consumption on Heart Disease")

# Update layout to make it more readable
fig_fruit.update_layout(xaxis_title="Age Group", yaxis_title="Median Fruit Consumption", legend_title="Heart Disease", xaxis_showgrid=False, yaxis_showgrid=False, plot_bgcolor='white')

# Display the plot
fig_fruit.show()

"""The bar chart depicts median fruit consumption across various age groups, comparing those with and without heart disease. In all age groups, individuals without heart disease consume more fruit than those with heart disease, suggesting a correlation between higher fruit intake and lower prevalence of heart disease. The age groups range from Young (18-24) to Elderly (70+), with this pattern consistent throughout."""

#Exercise vs. Heart Disease
fig1 = px.histogram(df_heart, x="Exercise", color='Heart_Disease', barmode='group',
                    title="Exercise vs. Heart Disease")
fig1.update_layout(xaxis_title="Exercise", yaxis_title="Count", legend_title="Heart Disease")
fig1.show()

"""The above plot shows less heart disease for patients who do exercise as compared to non-exercise patients.

# Correlation Analysis
"""

import plotly.express as px

# 1. Inspect Data
print("Unique values in 'Depression':", df_heart['Depression'].unique())
print("Unique values in 'Heart_Disease':", df_heart['Heart_Disease'].unique())

# 2. Convert to Numeric (assuming 'Yes' and 'No' values, adjust if different)
df_heart['Depression'] = df_heart['Depression'].map({'Yes': 1, 'No': 0})
df_heart['Heart_Disease'] = df_heart['Heart_Disease'].map({'Yes': 1, 'No': 0})

# 3. Visualize and Calculate Correlation
fig = px.histogram(df_heart, x="Depression", color="Heart_Disease",
                   title="Distribution of Depression by Heart Disease Status",
                   hover_data=["Depression", "Heart_Disease"])
fig.show()

correlation_value = df_heart['Depression'].corr(df_heart['Heart_Disease'])
print(f"\nThe correlation between depression and heart disease is: {correlation_value:.4f}")

# Select only the numerical columns
numerical_cols = df_heart.select_dtypes(include=['float64', 'int64'])

# Print information about the numerical columns
numerical_cols.info()
numerical_cols.columns

"""# Heat Map (Correlation Matrix)"""

categorical_columns = ['General_Health', 'Checkup', 'Exercise', 'Heart_Disease', 'Skin_Cancer', 'Other_Cancer', 'Depression', 'Diabetes', 'Arthritis', 'Sex']

numeric_columns = ['Heart_Disease', 'Depression', 'Height_cm', 'Weight_kg', 'BMI',
       'Alcohol_Consumption', 'Fruit_Consumption',
       'Green_Vegetables_Consumption', 'FriedPotato_Consumption']

# Compute the correlation coefficients
correlations = df_heart[numeric_columns].corr()

# Get correlations with respect to 'Heart_Disease'
heart_disease_correlations = correlations['Heart_Disease'].drop('Heart_Disease')

# Print the correlation coefficients with respect to 'Heart_Disease'
print("The correlation coefficients with respect to 'Heart_Disease':\n")
print(heart_disease_correlations)

"""The provided data indicates weak correlations between Heart_Disease and various health and lifestyle factors. Specifically, there's a slight positive relationship between heart disease and metrics like depression, weight, and BMI. On the other hand, factors such as alcohol consumption, fruit and green vegetable intake, and fried potato consumption show a marginal negative association, suggesting a possible reduced likelihood of heart disease with higher consumption. However, all these correlations are notably weak, so none of these factors is a strong predictor of heart disease on its own in this dataset. It's crucial to approach these findings with caution as correlation does not indicate causation."""

numeric_data = df_heart[numeric_columns]
correlation_matrix = numeric_data.corr()
correlation_matrix.head()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

"""**Conclusion of Exploratory Data Analysis**

1. Distribution of Heart Disease Patients based on General Health Rating: The majority of heart disease patients had average or poor general health ratings, indicating a potential association between general health and heart disease.
2. Variation in General Health Rating across Different Age Categories: The general health ratings varied among different age categories, with older individuals having lower average ratings.
3. Correlation between BMI and Heart Disease: There was a positive correlation between BMI and heart disease, suggesting that higher BMI values may increase the risk of heart disease.
4. Distribution of Heart Disease Patients based on Exercise Habits: A significant proportion of heart disease patients had sedentary lifestyles, indicating a potential relationship between exercise habits and heart disease.
5. Variation in Alcohol Consumption among Heart Disease Patients: Heart disease patients exhibited varying levels of alcohol consumption, with some individuals consuming alcohol in moderation and others abstaining completely.
6. Prevalence of Depression among Heart Disease Patients: A considerable number of heart disease patients also suffered from depression, highlighting the importance of mental health assessment and support in heart disease management.
7. Relationship between Heart Disease and Smoking History: There was a significant association between smoking history and heart disease prevalence, indicating that smoking may be a risk factor for heart disease.

**Predictive Analysis**

Since Heart_Disease is a binary variable (indicating presence or absence), a classification task is suitable. One common algorithm for binary classification tasks is Logistic Regression, but there are many others like Random Forest, Gradient Boosting, and Support Vector Machines, among others.


Here's a general outline:

1. Data Preprocessing
2. Splitting the data
3. Building the Model
4. Evaluating the Model
"""

df_heart.columns

df_predict=df_heart.copy()

"""Installing imbalanced-learn library for imbalanced data"""

!pip install imbalanced-learn

"""Installing xgboost library"""

!pip install xgboost

"""**Required libraries for data predictions:**


"""

import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import xgboost as xgb

# Separating predictors and target
X = df_predict.drop(columns='Heart_Disease')
y = df_predict['Heart_Disease']

"""One-hot Encoding"""

# One-hot encoding categorical variables
X = pd.get_dummies(X, drop_first=True)

"""**Stratified Train Test split of Heart_Disease and Dependent Variables**

By setting stratify=y in the train_test_split function, it ensures that the train and test sets have approximately the same percentage of samples of each target class as the complete set. This can be especially useful when dealing with imbalanced datasets.
"""

# Splitting into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""**SMOTE(Synthetic Minority Over-Sampling Technique)**

Let's use SMOTE (Synthetic Minority Over-Sampling Technique) for addressing class imbalance and displaying the confusion matrix.
"""

# Applying SMOTE for handling imbalance
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

"""**Feature Scaling The Data**

It is best practice is to estimate the mean and standard deviation of the training dataset and use these variables to scale the train and test dataset. This is to avoid any data leakage during the model evaluation process.



"""

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""Below code preprocesses the data, trains, and evaluates four different models (Random Forest, Gradient Boosting, Logistic Regression, AdaBoost and XGboost) on the task of predicting Heart_Disease based on the other columns in the dataset. The evaluations include accuracy, classification report, confusion matrix, and cross-validation results.

The code will also loop through each model using for loop, train the model on the training data, make predictions on the test set, and then perform a cross-validation. After evaluating each model, it will print out the accuracy, classification report, confusion matrix, and cross-validation results.

"""

# Initialize models
models = {
    'Random Forest': RandomForestClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'AdaBoost': AdaBoostClassifier(random_state=42),
    'XGBoost': xgb.XGBClassifier(random_state=42)
}

# Stratified K-Fold for cross-validation
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for name, model in models.items():
    print(f"\n\nModel for predicting Heart_Disease using {name}:\n")

    # Training
    model.fit(X_train, y_train)

    # Evaluation on training data
    y_train_pred = model.predict(X_train)
    print("Training Accuracy:", accuracy_score(y_train, y_train_pred))

    # Evaluation on test data
    y_pred = model.predict(X_test)
    print("Test Accuracy:", accuracy_score(y_test, y_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_pred, zero_division=1))

    # Displaying the confusion matrix
    conf_matrix = confusion_matrix(y_test, y_pred)
    sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title(f'Confusion Matrix - {name}')
    plt.show()

    # Cross-validation
    scores = cross_val_score(model, X, y, scoring='accuracy', cv=stratified_kfold, n_jobs=-1)
    print(f"\nCross-Validation Results for {name}:")
    print(f"Mean Accuracy: {np.mean(scores):.4f}")
    print(f"Standard Deviation: {np.std(scores):.4f}")

"""Random Forest:The first above output displays the performance metrics of a Random Forest model used to predict heart disease. The model has a high training accuracy of approximately 99.99% but a lower test accuracy of approximately 90.90%, indicating a potential overfit on the training data. The classification report reveals that the model has good precision (0.92) and recall (0.98) for classifying the negative class (0, no heart disease) but performs poorly on the positive class (1, heart disease) with a precision of 0.27 and a recall of 0.08.

The confusion matrix further illustrates this imbalance in performance: out of the total cases without heart disease (56,777), 55,773 are correctly predicted (true negatives), but there are 1,004 false positives. For the heart disease cases (4,994), only 379 are correctly predicted (true positives), while 4,615 are false negatives. This indicates that while the model is good at identifying those without heart disease, it struggles to correctly identify those with heart disease.

Gradient Boosting: Better balance between training and test accuracy than Random Forest, with improved identification of positive cases but still considerable false negatives.

Logistic Regression: Less overfitting with closer training and test accuracies, yet still struggles with low recall in heart disease prediction.

AdaBoost: Moderate overall accuracies with better performance on negative cases than positive, indicating challenges in identifying true positives effectively.

XGBoost: Exhibits possible overfitting with high training accuracy and moderate test accuracy, and like the others, shows a high precision but low recall for heart disease cases, pointing to difficulty in detecting true heart disease instances.

Across all models, there's a consistent theme of effectively identifying individuals without heart disease but a common difficulty in accurately detecting individuals with heart disease, as reflected by the high number of false negatives.

**Comparing each model:**

To compare the output of each model, we can create a summary table (or mapping table) that captures key evaluation metrics for each model. We can include metrics like training accuracy, test accuracy, mean cross-validation accuracy, and standard deviation of cross-validation scores. Below code will display a comparision table for all above 5 models.
"""

# Placeholder for the results
results = {
    'Model': [],
    'Training Accuracy': [],
    'Test Accuracy': [],
    'Mean CV Accuracy': [],
    'Std CV Accuracy': []
}

for name, model in models.items():
    # Training
    model.fit(X_train, y_train)

    # Evaluation on training data
    y_train_pred = model.predict(X_train)
    train_accuracy = accuracy_score(y_train, y_train_pred)

    # Evaluation on test data
    y_pred = model.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_pred)

    # Cross-validation
    scores = cross_val_score(model, X, y, scoring='accuracy', cv=stratified_kfold, n_jobs=-1)
    mean_cv = np.mean(scores)
    std_cv = np.std(scores)

    # Storing the results
    results['Model'].append(name)
    results['Training Accuracy'].append(train_accuracy)
    results['Test Accuracy'].append(test_accuracy)
    results['Mean CV Accuracy'].append(mean_cv)
    results['Std CV Accuracy'].append(std_cv)

# Converting results to a DataFrame for better visualization
df_results = pd.DataFrame(results)
df_results
#print(df_results)

"""**Conclusion**

The analysis of the performance metrics for various machine learning models on predicting Heart_Disease reveals distinct insights. The Random Forest model exhibits an exceptionally high training accuracy, nearing perfection at approximately 100%. Its test accuracy stands at a commendable 90.9%, indicating a robust capability to generalize on unseen data. Notably, its mean cross-validation accuracy is 91.86%, with an extremely low standard deviation, showcasing the model's consistent performance across different data folds.

The Gradient Boosting model, while having a slightly lower training accuracy than Random Forest, delivers a test accuracy of 86.72% and a mean CV accuracy of 91.95%. On the other hand, the Logistic Regression model, which is inherently linear, demonstrates a surprising efficiency with a training accuracy of 90.86% and a test accuracy of 88.08%. Its mean cross-validation accuracy remains competitive at 91.92%.

AdaBoost's performance is in a similar bracket as Gradient Boosting, with a mean CV accuracy of 91.88%. However, XGBoost emerges as one of the top contenders alongside Random Forest, boasting a training accuracy of 94.98% and a test accuracy of 91.44%. Its mean CV accuracy is a respectable 91.86%.

In summary, both Random Forest and XGBoost models emerge as the top performers in terms of test accuracy. However, all the models display comparable mean cross-validation accuracies, ranging between ~91.8% to ~91.9%. This consistency indicates that regardless of the model, the performance remains stable across different segments of the dataset. The choice of the optimal model would largely hinge on specific business requirements, the computational bandwidth, and other domain-specific criteria.
"""